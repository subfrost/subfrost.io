name: Deploy to GCP

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: us-central1
  SERVICE_NAME: subfrost-io
  REPOSITORY: subfrost-docker

jobs:
  deploy:
    name: Deploy to Cloud Run
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment || 'production' }}

    permissions:
      contents: read
      id-token: write  # Required for Workload Identity Federation

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # Workload Identity Federation (Recommended)
      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - name: Configure Docker for Artifact Registry
        run: |
          gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev --quiet

      - name: Build and Push Docker image
        run: |
          IMAGE="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.SERVICE_NAME }}"

          docker build \
            --tag "${IMAGE}:${{ github.sha }}" \
            --tag "${IMAGE}:latest" \
            --cache-from "${IMAGE}:latest" \
            .

          docker push "${IMAGE}:${{ github.sha }}"
          docker push "${IMAGE}:latest"

      - name: Get Cloud SQL connection name
        id: sql
        run: |
          CONNECTION=$(gcloud sql instances describe subfrost-postgres --format='value(connectionName)' 2>/dev/null || echo "")
          echo "connection=${CONNECTION}" >> $GITHUB_OUTPUT

      - name: Get Redis IP
        id: redis
        run: |
          REDIS_IP=$(gcloud redis instances describe subfrost-redis --region=${{ env.REGION }} --format='value(host)' 2>/dev/null || echo "")
          echo "ip=${REDIS_IP}" >> $GITHUB_OUTPUT

      - name: Deploy to Cloud Run
        run: |
          IMAGE="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.SERVICE_NAME }}:${{ github.sha }}"

          gcloud run deploy ${{ env.SERVICE_NAME }} \
            --image "${IMAGE}" \
            --platform managed \
            --region ${{ env.REGION }} \
            --allow-unauthenticated \
            --port 3000 \
            --cpu 1 \
            --memory 512Mi \
            --min-instances 0 \
            --max-instances 10 \
            --concurrency 80 \
            --timeout 60 \
            --vpc-connector subfrost-connector \
            --add-cloudsql-instances "${{ steps.sql.outputs.connection }}" \
            --set-env-vars "NODE_ENV=production" \
            --set-env-vars "NEXT_PUBLIC_NETWORK=mainnet" \
            --set-env-vars "REDIS_URL=redis://${{ steps.redis.outputs.ip }}:6379" \
            --set-env-vars "ADMIN_SECRET=${{ secrets.ADMIN_SECRET }}" \
            --set-secrets "DATABASE_URL=db-connection-string:latest"

      - name: Get Service URL
        id: service
        run: |
          URL=$(gcloud run services describe ${{ env.SERVICE_NAME }} \
            --region=${{ env.REGION }} \
            --format='value(status.url)')
          echo "url=${URL}" >> $GITHUB_OUTPUT
          echo "### Deployment Successful! :rocket:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Service URL:** ${URL}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Image:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY

      - name: Update Cloudflare DNS
        if: ${{ vars.CLOUDFLARE_DOMAIN != '' }}
        env:
          CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          DOMAIN="${{ vars.CLOUDFLARE_DOMAIN }}"
          TARGET="216.239.32.21"

          # Get Zone ID
          if [ -n "${{ vars.CLOUDFLARE_ZONE_ID }}" ]; then
            CF_ZONE_ID="${{ vars.CLOUDFLARE_ZONE_ID }}"
          else
            ROOT_DOMAIN=$(echo "$DOMAIN" | awk -F. '{print $(NF-1)"."$NF}')
            CF_ZONE_ID=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones?name=${ROOT_DOMAIN}" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json" | jq -r '.result[0].id')

            if [ "$CF_ZONE_ID" = "null" ] || [ -z "$CF_ZONE_ID" ]; then
              echo "Error: Could not find zone for ${ROOT_DOMAIN}"
              exit 1
            fi
          fi

          # Check for existing record
          RESPONSE=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/dns_records?name=${DOMAIN}" \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json")

          RECORD_ID=$(echo "$RESPONSE" | jq -r '.result[] | select(.type == "A" or .type == "CNAME") | .id' | head -1)

          if [ -n "$RECORD_ID" ]; then
            curl -s -X PUT "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/dns_records/${RECORD_ID}" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json" \
              --data "{\"type\":\"A\",\"name\":\"${DOMAIN}\",\"content\":\"${TARGET}\",\"ttl\":1,\"proxied\":false}" > /dev/null
            echo "Updated A record: ${DOMAIN} -> ${TARGET}"
          else
            curl -s -X POST "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/dns_records" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json" \
              --data "{\"type\":\"A\",\"name\":\"${DOMAIN}\",\"content\":\"${TARGET}\",\"ttl\":1,\"proxied\":false}" > /dev/null
            echo "Created A record: ${DOMAIN} -> ${TARGET}"
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Custom Domain:** https://${DOMAIN}" >> $GITHUB_STEP_SUMMARY

  deploy-media-server:
    name: Deploy Media Server
    runs-on: ubuntu-latest
    needs: deploy
    environment: ${{ github.event.inputs.environment || 'production' }}

    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.PROJECT_ID }}

      - name: Configure Docker for Artifact Registry
        run: |
          gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev --quiet

      - name: Build and Push Media Server image
        run: |
          IMAGE="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/subfrost-media-server"

          docker build \
            --tag "${IMAGE}:${{ github.sha }}" \
            --tag "${IMAGE}:latest" \
            ./media-server

          docker push "${IMAGE}:${{ github.sha }}"
          docker push "${IMAGE}:latest"

      - name: Deploy Media Server to Cloud Run
        run: |
          IMAGE="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/subfrost-media-server:${{ github.sha }}"

          gcloud run deploy subfrost-media-server \
            --image "${IMAGE}" \
            --platform managed \
            --region ${{ env.REGION }} \
            --allow-unauthenticated \
            --port 8080 \
            --cpu 2 \
            --memory 2Gi \
            --min-instances 0 \
            --max-instances 3 \
            --concurrency 5 \
            --timeout 3600 \
            --session-affinity \
            --set-env-vars "NODE_ENV=production" \
            --set-env-vars "GCS_BUCKET=subfrost-live-streams" \
            --set-env-vars "MAIN_APP_URL=https://${{ vars.CLOUDFLARE_DOMAIN }}" \
            --set-env-vars "STREAM_SECRET=${{ secrets.STREAM_SECRET }}"

      - name: Get Media Server URL
        id: media-service
        run: |
          URL=$(gcloud run services describe subfrost-media-server \
            --region=${{ env.REGION }} \
            --format='value(status.url)')
          echo "url=${URL}" >> $GITHUB_OUTPUT

      - name: Update media.subfrost.io DNS
        if: ${{ vars.CLOUDFLARE_ZONE_ID != '' }}
        env:
          CF_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          DOMAIN="media.subfrost.io"
          # Extract Cloud Run hostname from URL
          MEDIA_HOST=$(echo "${{ steps.media-service.outputs.url }}" | sed 's|https://||')
          CF_ZONE_ID="${{ vars.CLOUDFLARE_ZONE_ID }}"

          RESPONSE=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/dns_records?name=${DOMAIN}" \
            -H "Authorization: Bearer ${CF_API_TOKEN}" \
            -H "Content-Type: application/json")

          RECORD_ID=$(echo "$RESPONSE" | jq -r '.result[] | select(.type == "CNAME") | .id' | head -1)

          if [ -n "$RECORD_ID" ]; then
            curl -s -X PUT "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/dns_records/${RECORD_ID}" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json" \
              --data "{\"type\":\"CNAME\",\"name\":\"${DOMAIN}\",\"content\":\"${MEDIA_HOST}\",\"ttl\":1,\"proxied\":true}" > /dev/null
            echo "Updated CNAME: ${DOMAIN} -> ${MEDIA_HOST}"
          else
            curl -s -X POST "https://api.cloudflare.com/client/v4/zones/${CF_ZONE_ID}/dns_records" \
              -H "Authorization: Bearer ${CF_API_TOKEN}" \
              -H "Content-Type: application/json" \
              --data "{\"type\":\"CNAME\",\"name\":\"${DOMAIN}\",\"content\":\"${MEDIA_HOST}\",\"ttl\":1,\"proxied\":true}" > /dev/null
            echo "Created CNAME: ${DOMAIN} -> ${MEDIA_HOST}"
          fi

  migrate:
    name: Sync Database Schema
    runs-on: ubuntu-latest
    needs: deploy
    environment: ${{ github.event.inputs.environment || 'production' }}

    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Setup schema sync job
        run: |
          IMAGE="${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.SERVICE_NAME }}:${{ github.sha }}"
          SQL_CONNECTION=$(gcloud sql instances describe subfrost-postgres --format='value(connectionName)' 2>/dev/null || echo "")

          if [ -z "$SQL_CONNECTION" ]; then
            echo "Error: Cloud SQL instance not found"
            exit 1
          fi

          # Check if job exists
          if gcloud run jobs describe prisma-migrate --region=${{ env.REGION }} > /dev/null 2>&1; then
            echo "Updating existing migration job..."
            ACTION="update"
          else
            echo "Creating new migration job..."
            ACTION="create"
          fi

          # Create or update the job with correct configuration
          # Using 'db push' instead of 'migrate deploy' because:
          # - It's idempotent (safe to run multiple times)
          # - Doesn't require migration files
          # - Creates/updates tables to match schema
          gcloud run jobs $ACTION prisma-migrate \
            --region=${{ env.REGION }} \
            --image="${IMAGE}" \
            --max-retries=0 \
            --task-timeout=10m \
            --cpu=1 \
            --memory=512Mi \
            --vpc-connector=subfrost-connector \
            --add-cloudsql-instances="${SQL_CONNECTION}" \
            --set-secrets="DATABASE_URL=db-connection-string:latest" \
            --set-env-vars="NODE_ENV=production" \
            --command="prisma" \
            --args="db,push,--accept-data-loss,--skip-generate,--schema=./prisma/schema.prisma"

      - name: Sync database schema
        run: |
          echo "Syncing database schema with Prisma..."
          gcloud run jobs execute prisma-migrate \
            --region=${{ env.REGION }} \
            --wait
